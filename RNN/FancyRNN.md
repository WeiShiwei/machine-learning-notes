TODO

**Vanishing gradient problem** 

**Long Short-Term Memory (LSTM)**

**Gated Recurrent Units (GRU)**

**Is vanishing/exploding gradient just a RNN problem?**

**Bidirectional RNNs**

- BERT (**Bidirectional** Encoder Representations from Transformers) 

**Multi-layer RNNs**



#  LSTM

Long Short Term Memory

超生动图解LSTM和GRU：拯救循环神经网络的记忆障碍，就靠它们了

https://zhuanlan.zhihu.com/p/46981722



# GRU













![img](./images/v2-838b5aeac6a58f3c478fbae62c049f84_b.gif)

![img](https://pic1.zhimg.com/v2-9701d76234ace3f429bd566bf47b10bc_b.gif)







# 参考

1、超生动图解LSTM和GRU：拯救循环神经网络的记忆障碍，就靠它们了

https://zhuanlan.zhihu.com/p/46981722





