# 一、RNN

## RNN根据任务类型去划分有

### one to one(Vanilla RNN)

![image-20190322181345419](./images/image-20190322181345419.png)

### one to many

![image-20190322181523377](./images/image-20190322181523377.png)

### many to one

![image-20190322181557029](./images/image-20190322181557029.png)

### many to many

![image-20190322181628641](./images/image-20190322181628641.png)

![image-20190322181716461](./images/image-20190322181716461.png)

## vanilla rnn 计算公式

![image-20190322182429222](./images/image-20190322182429222.png)

![image-20190322182714153](./images/image-20190322182714153.png)

## Vanilla RNN Gradient Flow



# 二、Long Short Term Memory (LSTM)

超生动图解LSTM和GRU：拯救循环神经网络的记忆障碍，就靠它们了

https://zhuanlan.zhihu.com/p/46981722

# 三、GRU











![img](./images/v2-838b5aeac6a58f3c478fbae62c049f84_b.gif)

![img](https://pic1.zhimg.com/v2-9701d76234ace3f429bd566bf47b10bc_b.gif)







参考

1、cs231n_2017_lecture10 Recurrent Neural Networks

2、超生动图解LSTM和GRU：拯救循环神经网络的记忆障碍，就靠它们了

https://zhuanlan.zhihu.com/p/46981722





